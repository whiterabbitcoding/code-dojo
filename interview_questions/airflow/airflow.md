How would you describe Airflow?

Airflow is an open-source platform that is for workflow management. Airflow allows you to visualise, schedule and monitor your data pipelines. It is an ETL system

What problems are resolved by Airflow?

Some of the issues and problems resolved by Airflow include:

- maintaining audit trail of tasks
- scalable
- UI for monitoring and visualising ETLs
- Allows for event driven and cron scheduled dags

What are some features of Airflow?

- Helps schedule dags
- Uses python to write DAGs
- Can connect to various databases for information
- Can flexibly alter parameters in the UI that effect arguments in the DAG, useful for flexiblly changing monitoring thresholds

How does Apache Airflow act as a Solution?


- Failures: This tool assists in retrying in case there is a failure.
- Monitoring: It helps in checking if the status has been succeeded or failed.
- Dependency: There are two different types of dependencies, such as:
        Data Dependencies that assist in upstreaming the data
        Execution Dependencies that assist in deploying all the new changes
- Scalability: It helps centralize the scheduler
- Deployment: It is useful in deploying changes with ease
- Processing Historical Data: It is effective in backfilling historical data

What are the basic concepts in Airflow?

DAG
Task instance - task thats assigned to DAG
Operator - bash or python etc
Task- Parameterised instance

Define integrations of the airflow.

- apache plg
- amazon EMR
- kubernetes
- amazon s3
- amazon glue
- hadoop
- aws data lake

What airflow CLI commands do you know?


Airflow run is used for running a task
Airflow show DAG is used for showcasing tasks and their dependencies
Airflow task is used for debugging tasks
Airflow Webserver is used for beginning the GUI
Airflow backfill is used for running a specific part of DAG

Would you like to expand?

https://mindmajix.com/airflow-interview-questions
